#!/usr/bin/env bash
# Unified lint runner that executes both ast-grep rules and custom rules,
# outputting results in a consistent JSON format.
#
# Usage: lint-runner [--json]
#
# Output format (JSON stream, one object per finding):
# {
#   "ruleId": "rule-name",
#   "severity": "warning",
#   "message": "Description of the issue",
#   "note": "Additional context (optional)",
#   "file": "path/to/file.rs",
#   "range": { "start": { "line": 10, "column": 1 }, "end": { "line": 10, "column": 50 } },
#   "text": "matched text or context"
# }

set -euo pipefail

# Require yq - available in nix devshell
if ! command -v yq &>/dev/null; then
  echo "Error: yq is required but not found. Enter the nix devshell first." >&2
  exit 1
fi

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(cd "$SCRIPT_DIR/../.." && pwd)"
CUSTOM_RULES_DIR="$PROJECT_ROOT/lint/custom-rules"

output_json=false
if [[ "${1:-}" == "--json" ]]; then
  output_json=true
fi

# Collect all results into a temp file
results_file=$(mktemp)
trap 'rm -f "$results_file"' EXIT

run_ast_grep() {
  ast-grep scan --json=stream 2>/dev/null || true
}

run_custom_rules() {
  for rule_file in "$CUSTOM_RULES_DIR"/*.yml; do
    [[ -f "$rule_file" ]] || continue
    
    rule_id=$(yq '.id // ""' "$rule_file")
    rule_type=$(yq '.type // ""' "$rule_file")
    
    case "$rule_type" in
      command)
        run_cmd=$(yq '.run // ""' "$rule_file")
        [[ -z "$run_cmd" ]] && continue
        
        # Special handling for clippy with JSON output
        if [[ "$rule_id" == "clippy" ]]; then
          pushd "$PROJECT_ROOT" >/dev/null
          # Run clippy and parse its JSON output
          # Schema: { reason, message: { level, message, code, spans, children, rendered } }
          eval "$run_cmd" 2>&1 | while IFS= read -r line; do
            # Only process compiler-message lines with actual diagnostics (not notes)
            if echo "$line" | jq -e '.reason == "compiler-message" and .message.level != "note"' >/dev/null 2>&1; then
              echo "$line" | jq -c '
                .message as $msg |
                ($msg.spans // [])[] |
                select(.is_primary == true) |
                {
                  ruleId: ($msg.code.code // "clippy"),
                  severity: $msg.level,
                  message: $msg.message,
                  note: "",
                  file: .file_name,
                  range: {
                    start: { line: (.line_start - 1), column: (.column_start - 1) },
                    end: { line: (.line_end - 1), column: (.column_end - 1) }
                  },
                  text: ((.text // [{}])[0].text // "")
                }
              ' 2>/dev/null || true
            fi
          done
          popd >/dev/null
        fi
        ;;
        
      file-metric)
        check=$(yq '.check // ""' "$rule_file")
        max=$(yq '.max // 0' "$rule_file")
        severity=$(yq '.severity // "warning"' "$rule_file")
        message=$(yq '.message // ""' "$rule_file")
        note=$(yq '.note // ""' "$rule_file")
        mapfile -t files < <(yq '.files // [] | .[]' "$rule_file")
        mapfile -t ignores < <(yq '.ignores // [] | .[]' "$rule_file")
        
        case "$check" in
          line-count)
            shopt -s globstar nullglob
            for pattern in "${files[@]}"; do
              pushd "$PROJECT_ROOT" >/dev/null
              # Use eval to ensure glob expansion happens after globstar is set
              eval "for file in $pattern; do
                [[ -f \"\$file\" ]] || continue
                
                skip=false
                for ignore in \"\${ignores[@]}\"; do
                  if [[ \"\$file\" == \$ignore ]]; then
                    skip=true
                    break
                  fi
                done
                [[ \"\$skip\" == true ]] && continue
                
                lines=\$(wc -l < \"\$file\")
                if [[ \"\$lines\" -gt \"$max\" ]]; then
                  jq -n \\
                    --arg ruleId \"$rule_id\" \\
                    --arg severity \"$severity\" \\
                    --arg message \"$message\" \\
                    --arg note \"$note\" \\
                    --arg file \"\$file\" \\
                    --arg text \"\$lines lines\" \\
                    '{
                      ruleId: \$ruleId,
                      severity: \$severity,
                      message: \$message,
                      note: \$note,
                      file: \$file,
                      range: { start: { line: 0, column: 0 }, end: { line: 0, column: 0 } },
                      text: \$text
                    }'
                fi
              done"
              popd >/dev/null
            done
            shopt -u globstar nullglob
            ;;
        esac
        ;;
    esac
  done
}

# Run both and collect results
{
  run_ast_grep
  run_custom_rules
} > "$results_file"

if [[ "$output_json" == true ]]; then
  cat "$results_file"
else
  if [[ ! -s "$results_file" ]]; then
    echo "ok"
  else
    jq -s -r '
      # Deduplicate by file+line+column+ruleId before grouping
      unique_by([.file, .range.start.line, .range.start.column, .ruleId])
      | sort_by(.ruleId, .message, .note // "", .severity)
      | group_by([.ruleId, .message, .note // "", .severity])
      | .[]
      | "\(.[0].severity | ascii_upcase): \(.[0].ruleId) - \(.[0].message)\n"
        + (if (.[0].note? and .[0].note != "") then "NOTE: \(.[0].note)\n" else "" end)
        + (map("  - \(.file):\(.range.start.line+1):\(.range.start.column+1)" + (if .text != "" then " - \(.text)" else "" end)) | join("\n"))
        + "\n"
    ' "$results_file" 2>/dev/null || true
  fi
fi

# Exit with error if any findings were found
if [[ -s "$results_file" ]]; then
  exit 1
fi
